# üîç AUDIT COMPLET DU WORKFLOW D'ANALYSE AUDIO

**Date:** 2025-10-10
**Objectif:** Nettoyer et clarifier le workflow d'analyse (chords, BPM, key, structure, lyrics)

---

## üìä √âTAT ACTUEL (Ce qui fonctionne)

### ‚úÖ Modules install√©s et fonctionnels

1. **Madmom 0.17.dev0** (recompil√© depuis sources)
   - CNN Chord Recognition (CRF)
   - RNN Beat Tracking
   - Location: `/opt/stemtube/StemTube-dev/venv/lib/python3.12/site-packages/madmom/`
   - Mod√®les: 26 MB (beats, chords, chroma, key, notes, onsets, downbeats)

2. **MSAF 0.1.80** (Music Structure Analysis Framework)
   - Algorithmes: Foote, OLDA, SF, C-NMF, etc.
   - D√©tection de fronti√®res (boundaries)
   - **MAIS:** Pas de labeling s√©mantique

3. **faster-whisper** (Whisper optimis√©)
   - D√©tection de paroles
   - Mod√®les: base, small, medium, large-v3
   - GPU/CPU support

4. **librosa + soundfile + scipy**
   - Feature extraction
   - BPM/Key detection basique

---

## üîÑ WORKFLOW ACTUEL (download_manager.py lignes 598-697)

### √âtapes apr√®s t√©l√©chargement audio :

```python
# 1. Analyse BPM/Key (lignes 600-608)
analysis_results = self.analyze_audio_with_librosa(item.file_path)
# ‚Üí detected_bpm, detected_key, analysis_confidence

# 2. D√©tection d'accords (lignes 610-632)
from .chord_detector import analyze_audio_file
chords_data, beat_offset = analyze_audio_file(
    item.file_path,
    bpm=item.detected_bpm,
    detected_key=item.detected_key,
    use_madmom=True
)

# 3. D√©tection de structure (lignes 634-654)
from .advanced_structure_detector import detect_song_structure_advanced
structure_data = detect_song_structure_advanced(
    item.file_path,
    bpm=item.detected_bpm,
    use_msaf=True  # Utilise MSAF pour boundaries
)

# 4. D√©tection de paroles (lignes 656-681)
from .lyrics_detector import detect_song_lyrics
lyrics_data = detect_song_lyrics(
    item.file_path,
    model_size="large-v3",
    language=None,
    use_gpu=use_gpu
)

# 5. Sauvegarde en DB (lignes 683-697)
from .downloads_db import update_download_analysis
update_download_analysis(
    item.video_id,
    item.detected_bpm,
    item.detected_key,
    item.analysis_confidence,
    chords_data,
    beat_offset,
    structure_data,
    lyrics_data
)
```

---

## üö® PROBL√àMES IDENTIFI√âS

### 1. **Structure : pipeline unifi√© (r√©solu)**

Les anciens d√©tecteurs (`advanced_structure_detector.py`, `ssm_structure_detector.py`, `multimodal_structure_analyzer.py`) ont √©t√© supprim√©s.

- ‚úÖ Pipeline unique : `core/msaf_structure_detector.py`
- ‚úÖ `download_manager.py` appelle directement `detect_song_structure_msaf()`
- ‚úÖ Moins de maintenance, comportement pr√©visible

### 2. **Labels MSAF peu parlants**

**Constat :** MSAF renvoie souvent des labels g√©n√©riques (`A`, `B`, `C`).

**Am√©lioration possible :** Mapper les lettres vers `Section 1`, `Section 2`, ou proposer une table de correspondance personnalisable.

### 3. **D√©tection Whisper peut √©chouer**

**Probl√®me potentiel (ligne 680) :**
```python
lyrics_data = None  # Si exception
```

**Pas de d√©tection GPU correcte**, peut planter si CUDA mal configur√©

### 4. **D√©tecteurs de chords multiples**

**Fichiers :**
- `chord_detector.py` (interface principale)
- `madmom_chord_detector.py` (Madmom CRF)
- `hybrid_chord_detector.py` (Madmom beats + librosa chroma)

**Actuellement utilis√© :** `chord_detector.py` avec `use_madmom=True`
**Superflu :** `hybrid_chord_detector.py` (pas utilis√©)

---

## ‚úÖ CE QUI FONCTIONNE BIEN (√Ä GARDER)

1. **BPM/Key detection** (`analyze_audio_with_librosa`) ‚úÖ
   - Autocorrelation BPM
   - Chroma-based key detection
   - Fonctionne sans librosa/numba (Windows-compatible)

2. **Chord detection** (`chord_detector.py` ‚Üí `madmom_chord_detector.py`) ‚úÖ
   - Madmom CRF professional
   - Beat offset tracking
   - 24 chords (12 major + 12 minor)

3. **Sauvegarde DB** (`update_download_analysis`) ‚úÖ
   - Champs: `detected_bpm`, `detected_key`, `chords_data`, `beat_offset`, `structure_data`, `lyrics_data`

---

## üéØ PLAN DE NETTOYAGE PROPOS√â

### Phase 1: Pipeline retenu

- ‚úÖ Option unique : MSAF simple (`core/msaf_structure_detector.py`)
- ‚úÖ Pas de fusion accords/paroles, pas de SSM
- ‚û°Ô∏è Labels bruts fournis par MSAF (souvent `A`, `B`, `C`)

### Phase 2: Nettoyage effectu√©

- ‚ùå `hybrid_chord_detector.py` (toujours inutile, mais laiss√© pour archive)
- ‚ùå `advanced_structure_detector.py`, `ssm_structure_detector.py`, `multimodal_structure_analyzer.py` supprim√©s
- ‚úÖ `download_manager.py` appelle directement `detect_song_structure_msaf()`

### Phase 3: Am√©liorations potentielles

- Mapper les labels MSAF (`A`, `B`, `C`) vers `Section 1`, `Section 2`, etc.
- Exposer un script CLI pour imprimer la structure rapidement
- Ajouter un fallback librosa si MSAF indisponible

### Phase 4: Tester Whisper/GPU

**Probl√®me potentiel:** CUDA mal configur√© pour Whisper
**Solution:** Ajouter fallback CPU automatique

```python
# Dans lyrics_detector.py
try:
    model = WhisperModel(model_size, device="cuda" if use_gpu else "cpu")
except Exception as e:
    logger.warning(f"GPU failed, falling back to CPU: {e}")
    model = WhisperModel(model_size, device="cpu")
```

---

## üìã CHECKLIST DE V√âRIFICATION

- [ ] V√©rifier une analyse compl√®te (download ‚Üí MSAF ‚Üí DB)
- [ ] Contr√¥ler l'affichage timeline dans le mixer
- [ ] Mapper les labels MSAF si n√©cessaire (optionnel)
- [ ] Tester le fallback CPU de Whisper (GPU d√©branch√©)

---

## üéµ TRANSMISSION AU MIXER (√Ä V√âRIFIER)

### Donn√©es transmises :

```python
# Dans app.py (route /mixer)
EXTRACTION_INFO = {
    'video_id': video_id,
    'title': title,
    'detected_bpm': detected_bpm,
    'detected_key': detected_key,
    'chords_data': chords_data,
    'beat_offset': beat_offset,
    'structure_data': structure_data,
    'lyrics_data': lyrics_data,
    'stems': [...]
}
```

### Mixer JavaScript :

```javascript
// static/js/mixer/core.js
const chordsData = EXTRACTION_INFO.chords_data;
const bpm = EXTRACTION_INFO.detected_bpm;
const key = EXTRACTION_INFO.detected_key;
const structure = EXTRACTION_INFO.structure_data;

// Pitch/Tempo calibr√©s sur ces valeurs
simplePitchTempo.setOriginalBPM(bpm);
chordDisplay.setChords(chordsData, key);
```

**√Ä V√âRIFIER:** Que `structure_data` est bien affich√© quelque part dans l'UI

---

## üí° D√âCISIONS √Ä PRENDRE

1. **Labeling structure**
   - Par d√©faut: conserver labels MSAF (`A`, `B`, `C`)
   - Optionnel: mapper vers `Section 1`, `Section 2`, etc.

2. **Structure analyzer**
   - ‚úÖ D√©cision prise: MSAF unique (plus de multimodal)

3. **Whisper: quel mod√®le ?**
   - Actuel: `large-v3` (tr√®s lourd, ~3GB)
   - Alternative: `medium` (1.5GB, plus rapide)
   - **Recommandation:** Proposer un param√®tre dans la config

---

## üìù NOTES FINALES

**Conclusion:** Pipeline simplifi√© : MSAF unique, plus de redondance.
**Objectif court terme:** Option de mapping des labels + v√©rification UI.
**Timeline estim√©e:** 1h pour mapping + tests (si n√©cessaire).

**Points √† confirmer avec l'utilisateur:**
1. Souhaite-t-il un mapping automatique des labels (`A`, `B`, `C` ‚Üí `Section N`)?
2. Faut-il proposer un script CLI pour inspecter la structure ?
3. Doit-on exposer un param√®tre de choix de mod√®le Whisper (medium vs large) ?
